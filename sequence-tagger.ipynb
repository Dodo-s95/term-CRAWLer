{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bitterminologycondaef931532d8e947c7a884074a14664a41",
   "display_name": "Python 3.8.0 64-bit ('terminology': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings\n",
    "\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-11-05 14:03:45,157 Reading data from .\n",
      "2020-11-05 14:03:45,158 Train: train.txt\n",
      "2020-11-05 14:03:45,158 Dev: dev.txt\n",
      "2020-11-05 14:03:45,158 Test: test.txt\n"
     ]
    }
   ],
   "source": [
    "# define columns\n",
    "columns = {0: 'text', 1: 'bio'}\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = './'\n",
    "\n",
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='train.txt',\n",
    "                              test_file='test.txt',\n",
    "                              dev_file='dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "George <B> Washington <I> went to Washington <B>\nGeorge <B> Washington <I> went to Washington <B>\n"
     ]
    }
   ],
   "source": [
    "print(corpus.train[0].to_tagged_string('bio'))\n",
    "print(corpus.test[0].to_tagged_string('bio'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " - loss 4.26976776 - samples/sec: 1518.51 - lr: 0.050000\n",
      "2020-11-05 14:25:58,829 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:58,830 EPOCH 10 done: loss 4.2698 - lr 0.0500000\n",
      "2020-11-05 14:25:58,841 DEV : loss 3.9461450576782227 - score 0.6\n",
      "2020-11-05 14:25:58,842 BAD EPOCHS (no improvement): 3\n",
      "2020-11-05 14:25:58,843 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:58,863 epoch 11 - iter 1/1 - loss 4.51802158 - samples/sec: 1739.16 - lr: 0.050000\n",
      "2020-11-05 14:25:58,864 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:58,864 EPOCH 11 done: loss 4.5180 - lr 0.0500000\n",
      "2020-11-05 14:25:58,875 DEV : loss 3.788315534591675 - score 0.6\n",
      "Epoch    11: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2020-11-05 14:25:58,877 BAD EPOCHS (no improvement): 4\n",
      "2020-11-05 14:25:58,878 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:58,897 epoch 12 - iter 1/1 - loss 4.09131289 - samples/sec: 1798.35 - lr: 0.025000\n",
      "2020-11-05 14:25:58,898 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:58,899 EPOCH 12 done: loss 4.0913 - lr 0.0250000\n",
      "2020-11-05 14:25:58,911 DEV : loss 3.6964974403381348 - score 0.6\n",
      "2020-11-05 14:25:58,912 BAD EPOCHS (no improvement): 1\n",
      "2020-11-05 14:25:58,913 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:58,934 epoch 13 - iter 1/1 - loss 3.96606326 - samples/sec: 1577.97 - lr: 0.025000\n",
      "2020-11-05 14:25:58,935 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:58,936 EPOCH 13 done: loss 3.9661 - lr 0.0250000\n",
      "2020-11-05 14:25:58,947 DEV : loss 3.5943055152893066 - score 0.6\n",
      "2020-11-05 14:25:58,948 BAD EPOCHS (no improvement): 2\n",
      "2020-11-05 14:25:58,949 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:58,967 epoch 14 - iter 1/1 - loss 3.95352459 - samples/sec: 1801.34 - lr: 0.025000\n",
      "2020-11-05 14:25:58,968 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:58,969 EPOCH 14 done: loss 3.9535 - lr 0.0250000\n",
      "2020-11-05 14:25:58,981 DEV : loss 3.506870746612549 - score 0.6\n",
      "2020-11-05 14:25:58,982 BAD EPOCHS (no improvement): 3\n",
      "2020-11-05 14:25:58,984 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:58,999 epoch 15 - iter 1/1 - loss 3.43884468 - samples/sec: 2303.02 - lr: 0.025000\n",
      "2020-11-05 14:25:59,000 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,001 EPOCH 15 done: loss 3.4388 - lr 0.0250000\n",
      "2020-11-05 14:25:59,011 DEV : loss 3.3826894760131836 - score 0.6\n",
      "Epoch    15: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2020-11-05 14:25:59,011 BAD EPOCHS (no improvement): 4\n",
      "2020-11-05 14:25:59,012 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,032 epoch 16 - iter 1/1 - loss 3.42282391 - samples/sec: 1680.87 - lr: 0.012500\n",
      "2020-11-05 14:25:59,033 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,034 EPOCH 16 done: loss 3.4228 - lr 0.0125000\n",
      "2020-11-05 14:25:59,045 DEV : loss 3.2865047454833984 - score 0.6\n",
      "2020-11-05 14:25:59,046 BAD EPOCHS (no improvement): 1\n",
      "2020-11-05 14:25:59,047 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,061 epoch 17 - iter 1/1 - loss 3.29278231 - samples/sec: 2447.31 - lr: 0.012500\n",
      "2020-11-05 14:25:59,062 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,063 EPOCH 17 done: loss 3.2928 - lr 0.0125000\n",
      "2020-11-05 14:25:59,079 DEV : loss 3.232234001159668 - score 0.6\n",
      "2020-11-05 14:25:59,080 BAD EPOCHS (no improvement): 2\n",
      "2020-11-05 14:25:59,081 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,101 epoch 18 - iter 1/1 - loss 3.51819873 - samples/sec: 1634.51 - lr: 0.012500\n",
      "2020-11-05 14:25:59,103 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,104 EPOCH 18 done: loss 3.5182 - lr 0.0125000\n",
      "2020-11-05 14:25:59,119 DEV : loss 3.187985897064209 - score 0.6\n",
      "2020-11-05 14:25:59,120 BAD EPOCHS (no improvement): 3\n",
      "2020-11-05 14:25:59,122 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,137 epoch 19 - iter 1/1 - loss 3.53353119 - samples/sec: 2291.70 - lr: 0.012500\n",
      "2020-11-05 14:25:59,138 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,139 EPOCH 19 done: loss 3.5335 - lr 0.0125000\n",
      "2020-11-05 14:25:59,148 DEV : loss 3.10137939453125 - score 0.6\n",
      "Epoch    19: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2020-11-05 14:25:59,149 BAD EPOCHS (no improvement): 4\n",
      "2020-11-05 14:25:59,150 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,165 epoch 20 - iter 1/1 - loss 3.87877679 - samples/sec: 2309.60 - lr: 0.006250\n",
      "2020-11-05 14:25:59,166 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,167 EPOCH 20 done: loss 3.8788 - lr 0.0062500\n",
      "2020-11-05 14:25:59,184 DEV : loss 3.0797157287597656 - score 0.6\n",
      "2020-11-05 14:25:59,185 BAD EPOCHS (no improvement): 1\n",
      "2020-11-05 14:25:59,185 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,203 epoch 21 - iter 1/1 - loss 3.28299093 - samples/sec: 1939.76 - lr: 0.006250\n",
      "2020-11-05 14:25:59,204 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,205 EPOCH 21 done: loss 3.2830 - lr 0.0062500\n",
      "2020-11-05 14:25:59,218 DEV : loss 3.0515670776367188 - score 0.6\n",
      "2020-11-05 14:25:59,219 BAD EPOCHS (no improvement): 2\n",
      "2020-11-05 14:25:59,221 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,239 epoch 22 - iter 1/1 - loss 3.30701351 - samples/sec: 1866.26 - lr: 0.006250\n",
      "2020-11-05 14:25:59,240 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,241 EPOCH 22 done: loss 3.3070 - lr 0.0062500\n",
      "2020-11-05 14:25:59,252 DEV : loss 3.0226430892944336 - score 0.6\n",
      "2020-11-05 14:25:59,253 BAD EPOCHS (no improvement): 3\n",
      "2020-11-05 14:25:59,254 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,279 epoch 23 - iter 1/1 - loss 2.95704508 - samples/sec: 1313.59 - lr: 0.006250\n",
      "2020-11-05 14:25:59,281 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,285 EPOCH 23 done: loss 2.9570 - lr 0.0062500\n",
      "2020-11-05 14:25:59,302 DEV : loss 2.9923529624938965 - score 0.6\n",
      "Epoch    23: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2020-11-05 14:25:59,303 BAD EPOCHS (no improvement): 4\n",
      "2020-11-05 14:25:59,304 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,331 epoch 24 - iter 1/1 - loss 2.88369751 - samples/sec: 1523.71 - lr: 0.003125\n",
      "2020-11-05 14:25:59,332 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,335 EPOCH 24 done: loss 2.8837 - lr 0.0031250\n",
      "2020-11-05 14:25:59,355 DEV : loss 2.9764490127563477 - score 0.6\n",
      "2020-11-05 14:25:59,359 BAD EPOCHS (no improvement): 1\n",
      "2020-11-05 14:25:59,360 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,385 epoch 25 - iter 1/1 - loss 2.94291353 - samples/sec: 1402.38 - lr: 0.003125\n",
      "2020-11-05 14:25:59,386 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,388 EPOCH 25 done: loss 2.9429 - lr 0.0031250\n",
      "2020-11-05 14:25:59,403 DEV : loss 2.959132194519043 - score 0.6\n",
      "2020-11-05 14:25:59,404 BAD EPOCHS (no improvement): 2\n",
      "2020-11-05 14:25:59,406 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,433 epoch 26 - iter 1/1 - loss 3.05314541 - samples/sec: 1353.64 - lr: 0.003125\n",
      "2020-11-05 14:25:59,434 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,434 EPOCH 26 done: loss 3.0531 - lr 0.0031250\n",
      "2020-11-05 14:25:59,448 DEV : loss 2.943161964416504 - score 0.6\n",
      "2020-11-05 14:25:59,449 BAD EPOCHS (no improvement): 3\n",
      "2020-11-05 14:25:59,451 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,472 epoch 27 - iter 1/1 - loss 2.87603903 - samples/sec: 1608.34 - lr: 0.003125\n",
      "2020-11-05 14:25:59,474 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,475 EPOCH 27 done: loss 2.8760 - lr 0.0031250\n",
      "2020-11-05 14:25:59,491 DEV : loss 2.9279541969299316 - score 0.6\n",
      "Epoch    27: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2020-11-05 14:25:59,493 BAD EPOCHS (no improvement): 4\n",
      "2020-11-05 14:25:59,496 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,518 epoch 28 - iter 1/1 - loss 2.71049023 - samples/sec: 1629.53 - lr: 0.001563\n",
      "2020-11-05 14:25:59,519 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,519 EPOCH 28 done: loss 2.7105 - lr 0.0015625\n",
      "2020-11-05 14:25:59,531 DEV : loss 2.9193038940429688 - score 0.6\n",
      "2020-11-05 14:25:59,532 BAD EPOCHS (no improvement): 1\n",
      "2020-11-05 14:25:59,532 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,550 epoch 29 - iter 1/1 - loss 3.28241014 - samples/sec: 2234.80 - lr: 0.001563\n",
      "2020-11-05 14:25:59,551 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,551 EPOCH 29 done: loss 3.2824 - lr 0.0015625\n",
      "2020-11-05 14:25:59,562 DEV : loss 2.912046432495117 - score 0.6\n",
      "2020-11-05 14:25:59,563 BAD EPOCHS (no improvement): 2\n",
      "2020-11-05 14:25:59,563 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,581 epoch 30 - iter 1/1 - loss 3.20373297 - samples/sec: 1864.19 - lr: 0.001563\n",
      "2020-11-05 14:25:59,582 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,585 EPOCH 30 done: loss 3.2037 - lr 0.0015625\n",
      "2020-11-05 14:25:59,598 DEV : loss 2.9050798416137695 - score 0.6\n",
      "2020-11-05 14:25:59,599 BAD EPOCHS (no improvement): 3\n",
      "2020-11-05 14:25:59,601 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,621 epoch 31 - iter 1/1 - loss 2.99181795 - samples/sec: 2022.97 - lr: 0.001563\n",
      "2020-11-05 14:25:59,622 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,622 EPOCH 31 done: loss 2.9918 - lr 0.0015625\n",
      "2020-11-05 14:25:59,634 DEV : loss 2.8979625701904297 - score 0.6\n",
      "Epoch    31: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2020-11-05 14:25:59,635 BAD EPOCHS (no improvement): 4\n",
      "2020-11-05 14:25:59,636 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,654 epoch 32 - iter 1/1 - loss 2.79220200 - samples/sec: 1927.67 - lr: 0.000781\n",
      "2020-11-05 14:25:59,655 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,655 EPOCH 32 done: loss 2.7922 - lr 0.0007813\n",
      "2020-11-05 14:25:59,667 DEV : loss 2.8942294120788574 - score 0.6\n",
      "2020-11-05 14:25:59,668 BAD EPOCHS (no improvement): 1\n",
      "2020-11-05 14:25:59,672 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,691 epoch 33 - iter 1/1 - loss 3.60699892 - samples/sec: 1885.32 - lr: 0.000781\n",
      "2020-11-05 14:25:59,692 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,693 EPOCH 33 done: loss 3.6070 - lr 0.0007813\n",
      "2020-11-05 14:25:59,705 DEV : loss 2.891697883605957 - score 0.6\n",
      "2020-11-05 14:25:59,707 BAD EPOCHS (no improvement): 2\n",
      "2020-11-05 14:25:59,709 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,732 epoch 34 - iter 1/1 - loss 3.02788591 - samples/sec: 1500.24 - lr: 0.000781\n",
      "2020-11-05 14:25:59,733 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,734 EPOCH 34 done: loss 3.0279 - lr 0.0007813\n",
      "2020-11-05 14:25:59,746 DEV : loss 2.8881583213806152 - score 0.6\n",
      "2020-11-05 14:25:59,747 BAD EPOCHS (no improvement): 3\n",
      "2020-11-05 14:25:59,747 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,767 epoch 35 - iter 1/1 - loss 3.04212761 - samples/sec: 1705.43 - lr: 0.000781\n",
      "2020-11-05 14:25:59,768 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,769 EPOCH 35 done: loss 3.0421 - lr 0.0007813\n",
      "2020-11-05 14:25:59,781 DEV : loss 2.8843064308166504 - score 0.6\n",
      "Epoch    35: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2020-11-05 14:25:59,783 BAD EPOCHS (no improvement): 4\n",
      "2020-11-05 14:25:59,784 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,803 epoch 36 - iter 1/1 - loss 2.93009043 - samples/sec: 1795.27 - lr: 0.000391\n",
      "2020-11-05 14:25:59,804 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,805 EPOCH 36 done: loss 2.9301 - lr 0.0003906\n",
      "2020-11-05 14:25:59,818 DEV : loss 2.8824968338012695 - score 0.6\n",
      "2020-11-05 14:25:59,821 BAD EPOCHS (no improvement): 1\n",
      "2020-11-05 14:25:59,825 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,856 epoch 37 - iter 1/1 - loss 3.04722404 - samples/sec: 1176.25 - lr: 0.000391\n",
      "2020-11-05 14:25:59,857 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,859 EPOCH 37 done: loss 3.0472 - lr 0.0003906\n",
      "2020-11-05 14:25:59,875 DEV : loss 2.8807477951049805 - score 0.6\n",
      "2020-11-05 14:25:59,876 BAD EPOCHS (no improvement): 2\n",
      "2020-11-05 14:25:59,878 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,899 epoch 38 - iter 1/1 - loss 3.62830544 - samples/sec: 1797.62 - lr: 0.000391\n",
      "2020-11-05 14:25:59,900 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,901 EPOCH 38 done: loss 3.6283 - lr 0.0003906\n",
      "2020-11-05 14:25:59,911 DEV : loss 2.8795204162597656 - score 0.6\n",
      "2020-11-05 14:25:59,914 BAD EPOCHS (no improvement): 3\n",
      "2020-11-05 14:25:59,915 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,939 epoch 39 - iter 1/1 - loss 3.03918028 - samples/sec: 1479.65 - lr: 0.000391\n",
      "2020-11-05 14:25:59,941 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,943 EPOCH 39 done: loss 3.0392 - lr 0.0003906\n",
      "2020-11-05 14:25:59,958 DEV : loss 2.877711296081543 - score 0.6\n",
      "Epoch    39: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2020-11-05 14:25:59,959 BAD EPOCHS (no improvement): 4\n",
      "2020-11-05 14:25:59,964 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,992 epoch 40 - iter 1/1 - loss 2.99487162 - samples/sec: 1206.08 - lr: 0.000195\n",
      "2020-11-05 14:25:59,994 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:25:59,995 EPOCH 40 done: loss 2.9949 - lr 0.0001953\n",
      "2020-11-05 14:26:00,013 DEV : loss 2.8769021034240723 - score 0.6\n",
      "2020-11-05 14:26:00,014 BAD EPOCHS (no improvement): 1\n",
      "2020-11-05 14:26:00,015 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:26:00,038 epoch 41 - iter 1/1 - loss 2.78556633 - samples/sec: 1649.60 - lr: 0.000195\n",
      "2020-11-05 14:26:00,040 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:26:00,041 EPOCH 41 done: loss 2.7856 - lr 0.0001953\n",
      "2020-11-05 14:26:00,056 DEV : loss 2.875983715057373 - score 0.6\n",
      "2020-11-05 14:26:00,057 BAD EPOCHS (no improvement): 2\n",
      "2020-11-05 14:26:00,058 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:26:00,079 epoch 42 - iter 1/1 - loss 3.45879602 - samples/sec: 1587.89 - lr: 0.000195\n",
      "2020-11-05 14:26:00,081 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:26:00,082 EPOCH 42 done: loss 3.4588 - lr 0.0001953\n",
      "2020-11-05 14:26:00,094 DEV : loss 2.8753609657287598 - score 0.6\n",
      "2020-11-05 14:26:00,095 BAD EPOCHS (no improvement): 3\n",
      "2020-11-05 14:26:00,097 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:26:00,116 epoch 43 - iter 1/1 - loss 2.81556273 - samples/sec: 1897.53 - lr: 0.000195\n",
      "2020-11-05 14:26:00,117 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:26:00,118 EPOCH 43 done: loss 2.8156 - lr 0.0001953\n",
      "2020-11-05 14:26:00,131 DEV : loss 2.874415397644043 - score 0.6\n",
      "Epoch    43: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2020-11-05 14:26:00,133 BAD EPOCHS (no improvement): 4\n",
      "2020-11-05 14:26:00,139 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:26:00,140 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:26:00,142 learning rate too small - quitting training!\n",
      "2020-11-05 14:26:00,143 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:26:02,538 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-05 14:26:02,540 Testing using best model ...\n",
      "2020-11-05 14:26:02,543 loading file resources/taggers/example-pos/best-model.pt\n",
      "2020-11-05 14:26:04,182 \t0.8\n",
      "2020-11-05 14:26:04,182 \n",
      "Results:\n",
      "- F-score (micro): 0.8\n",
      "- F-score (macro): 0.7778\n",
      "- Accuracy (incl. no class): 0.8\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B     1.0000    0.5000    0.6667         2\n",
      "           I     0.5000    1.0000    0.6667         1\n",
      "           O     1.0000    1.0000    1.0000         2\n",
      "\n",
      "    accuracy                         0.8000         5\n",
      "   macro avg     0.8333    0.8333    0.7778         5\n",
      "weighted avg     0.9000    0.8000    0.8000         5\n",
      "\n",
      "2020-11-05 14:26:04,183 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'test_score': 0.8,\n",
       " 'dev_score_history': [0.0,\n",
       "  0.4,\n",
       "  0.8,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6],\n",
       " 'train_loss_history': [11.853506088256836,\n",
       "  9.45061206817627,\n",
       "  8.123458862304688,\n",
       "  6.927969932556152,\n",
       "  6.11998987197876,\n",
       "  5.569140434265137,\n",
       "  5.19166374206543,\n",
       "  4.795567512512207,\n",
       "  4.603191375732422,\n",
       "  4.269767761230469,\n",
       "  4.518021583557129,\n",
       "  4.091312885284424,\n",
       "  3.9660632610321045,\n",
       "  3.953524589538574,\n",
       "  3.438844680786133,\n",
       "  3.422823905944824,\n",
       "  3.2927823066711426,\n",
       "  3.5181987285614014,\n",
       "  3.5335311889648438,\n",
       "  3.878776788711548,\n",
       "  3.2829909324645996,\n",
       "  3.307013511657715,\n",
       "  2.957045078277588,\n",
       "  2.883697509765625,\n",
       "  2.94291353225708,\n",
       "  3.053145408630371,\n",
       "  2.8760390281677246,\n",
       "  2.7104902267456055,\n",
       "  3.282410144805908,\n",
       "  3.203732967376709,\n",
       "  2.9918179512023926,\n",
       "  2.7922019958496094,\n",
       "  3.606998920440674,\n",
       "  3.027885913848877,\n",
       "  3.0421276092529297,\n",
       "  2.9300904273986816,\n",
       "  3.0472240447998047,\n",
       "  3.628305435180664,\n",
       "  3.039180278778076,\n",
       "  2.9948716163635254,\n",
       "  2.7855663299560547,\n",
       "  3.4587960243225098,\n",
       "  2.8155627250671387],\n",
       " 'dev_loss_history': [9.459952354431152,\n",
       "  7.75466775894165,\n",
       "  6.617725372314453,\n",
       "  5.995150089263916,\n",
       "  5.598211765289307,\n",
       "  5.097630023956299,\n",
       "  4.622892379760742,\n",
       "  4.396482467651367,\n",
       "  4.147464275360107,\n",
       "  3.9461450576782227,\n",
       "  3.788315534591675,\n",
       "  3.6964974403381348,\n",
       "  3.5943055152893066,\n",
       "  3.506870746612549,\n",
       "  3.3826894760131836,\n",
       "  3.2865047454833984,\n",
       "  3.232234001159668,\n",
       "  3.187985897064209,\n",
       "  3.10137939453125,\n",
       "  3.0797157287597656,\n",
       "  3.0515670776367188,\n",
       "  3.0226430892944336,\n",
       "  2.9923529624938965,\n",
       "  2.9764490127563477,\n",
       "  2.959132194519043,\n",
       "  2.943161964416504,\n",
       "  2.9279541969299316,\n",
       "  2.9193038940429688,\n",
       "  2.912046432495117,\n",
       "  2.9050798416137695,\n",
       "  2.8979625701904297,\n",
       "  2.8942294120788574,\n",
       "  2.891697883605957,\n",
       "  2.8881583213806152,\n",
       "  2.8843064308166504,\n",
       "  2.8824968338012695,\n",
       "  2.8807477951049805,\n",
       "  2.8795204162597656,\n",
       "  2.877711296081543,\n",
       "  2.8769021034240723,\n",
       "  2.875983715057373,\n",
       "  2.8753609657287598,\n",
       "  2.874415397644043]}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'bio'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary)\n",
    "\n",
    "# 4. initialize embeddings\n",
    "embedding_types = [\n",
    "\n",
    "    WordEmbeddings('glove'),\n",
    "\n",
    "    # comment in this line to use character embeddings\n",
    "    # CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings\n",
    "    # FlairEmbeddings('news-forward'),\n",
    "    # FlairEmbeddings('news-backward'),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)\n",
    "\n",
    "# 6. initialize trainer\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# 7. start training\n",
    "trainer.train('resources/taggers/example-pos',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}